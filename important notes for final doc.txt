0) first - explain the project goal
1) then explain about learning images via transformers (we didnt study it in class).
2) then compare why it is different from cnn
3) then say how we do it
4) talk about things we ran into:
the best data we found had 2k images, because we had to have bboxes (****explain why****) for the cnn to work. therefore we went to another approach - taking pre trained model and fine tune it with our data - this cause a robust and more efficiant training for our project purpose:
2K images is enough for fine-tuning pre-trained models
26 classes = diverse enough for meaningful recipes
Roboflow makes export trivial (YOLO format ready)

one major problem we had to solve: we may need to manually curate a "Hard Occlusion" test subset — but that's part of our novelty contribution anyway!

few key things we focus on:
1	Occlusion Difficulty Split - Classify test images into Easy/Medium/Hard based on bounding box overlap (IoU between objects)
2	Confidence Calibration Study - Analyze: Is high confidence = correct? Plot reliability diagrams, find optimal threshold, compare CNN vs Transformer calibration
3	Attention Map Visualization - Show WHERE RT-DETR "looks" on occluded images — proves it uses global context
4	Performance Graphs - mAP, Recall, Precision curves across difficulty levels + confidence thresholds

4.5) make complex - adding noise, occulations etc...
5) show resaults - talk about hyper params, matrixes, praphs, plots
6) conclusion - reguarding occulations:
What it does: For N boxes, computes IoU for all pairs.
Example: 4 boxes → 6 pairs → returns max of those 6 IoUs. with this max we decice if its easy/medium/hard.
we chose this matrix. we could add more like: Object count, Object size variance, Edge proximity, Class confusion, Visibility percentage. but we chose to not focus it because it will get the project to other dimantions we are not interested now. for future projects we can look into these paths.

7) about data augmentations: Key insight: Ultralytics provides a unified API for both models, which means:
Same training parameters
Same data format (YOLO format labels)
Same .predict() method for inference
Built-in online augmentations (mosaic, flip, scale, HSV) during training
That's why you don't need Roboflow augmentations - ultralytics handles it automatically during model.train().


How to Reach 85-90% mAP@50:
Quick Wins (Can do now):
1. Train Longer


epochs=100  # Instead of 50
patience=20  # Instead of 10
You stopped at epoch 28-49, might not have fully converged.

2. Use Larger Models


# Instead of yolov8n (nano)
yolo_model = YOLO('yolov8m.pt')  # medium (+10-15% mAP typically)

# Instead of rtdetr-l (large)  
rtdetr_model = RTDETR('rtdetr-x.pt')  # extra-large (+5-10% mAP)
3. Data Augmentation (Ultralytics does this automatically, but you can boost it)


model.train(
    ...,
    hsv_h=0.015,      # Hue augmentation
    hsv_s=0.7,        # Saturation
    hsv_v=0.4,        # Value
    degrees=10,       # Rotation
    translate=0.1,    # Translation
    scale=0.5,        # Zoom
    mosaic=1.0,       # Mosaic augmentation
)
My Recommendation:
For this project, keep your current results because:

Training longer/bigger models takes 5-10x more time
Your 67-70% is respectable for this task
The occlusion experiment will work just as well
You can mention "future work: larger models, more data" in your report
If you really want higher scores:

Easiest: Train yolov8m and rtdetr-x for 100 epochs (~6-8 hours)
Expected gain: +10-15% mAP → 80-85% range


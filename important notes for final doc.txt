0) first - explain the project goal
1) then explain about learning images via transformers (we didnt study it in class).
2) then compare why it is different from cnn
3) then say how we do it
4) talk about things we ran into:
the best data we found had 2k images, because we had to have bboxes (****explain why****) for the cnn to work. therefore we went to another approach - taking pre trained model and fine tune it with our data - this cause a robust and more efficiant training for our project purpose:
2K images is enough for fine-tuning pre-trained models
26 classes = diverse enough for meaningful recipes
Roboflow makes export trivial (YOLO format ready)

one major problem we had to solve: we may need to manually curate a "Hard Occlusion" test subset — but that's part of our novelty contribution anyway!

few key things we focus on:
1	Occlusion Difficulty Split - Classify test images into Easy/Medium/Hard based on bounding box overlap (IoU between objects)
2	Confidence Calibration Study - Analyze: Is high confidence = correct? Plot reliability diagrams, find optimal threshold, compare CNN vs Transformer calibration
3	Attention Map Visualization - Show WHERE RT-DETR "looks" on occluded images — proves it uses global context
4	Performance Graphs - mAP, Recall, Precision curves across difficulty levels + confidence thresholds

4.5) make complex - adding noise, occulations etc...
5) show resaults - talk about hyper params, matrixes, praphs, plots
6) conclusion



reguarding occulations:
What it does: For N boxes, computes IoU for all pairs.
Example: 4 boxes → 6 pairs → returns max of those 6 IoUs. with this max we decice if its easy/medium/hard.
we chose this matrix. we could add more like: Object count, Object size variance, Edge proximity, Class confusion, Visibility percentage. but we chose to not focus it because it will get the project to other dimantions we are not interested now. for future projects we can look into these paths.


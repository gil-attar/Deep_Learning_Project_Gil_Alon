{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion Robustness Evaluation\n",
    "\n",
    "**Objective:** Compare YOLOv8 vs RT-DETR performance degradation under synthetic occlusions.\n",
    "\n",
    "**Hypothesis:** RT-DETR (Transformer) should degrade more gracefully than YOLOv8 (CNN) as occlusion increases, because global attention can reason about partial objects better than local convolutions.\n",
    "\n",
    "**Experiment Design:**\n",
    "- Fixed weights (no retraining!)\n",
    "- Same 400 test images with different occlusion levels\n",
    "- 4 test sets: 0%, 20%, 40%, 60% occlusion\n",
    "- Same occlusion patterns for both models (seed=42)\n",
    "- Generate 24 JSON files (2 models × 4 levels × 3 files)\n",
    "\n",
    "**Runtime:** ~30-40 minutes total on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Clone repository if not already present\n",
    "    if not os.path.exists('/content/Deep_Learning_Gil_Alon'):\n",
    "        !git clone https://github.com/YOUR_USERNAME/Deep_Learning_Gil_Alon.git\n",
    "    os.chdir('/content/Deep_Learning_Gil_Alon')\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    # Assume we're in notebooks/ directory\n",
    "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "        os.chdir('..')\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab only)\n",
    "if IN_COLAB:\n",
    "    !pip install -q ultralytics roboflow pyyaml pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU availability\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: No GPU detected! Evaluation will be very slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset (Colab Only)\n",
    "\n",
    "**NOTE:** If running locally, ensure dataset already exists in `data/raw/test/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Roboflow API key here\n",
    "ROBOFLOW_API_KEY = \"YOUR_API_KEY_HERE\"  # ← REPLACE THIS!\n",
    "\n",
    "# Dataset version\n",
    "DATASET_VERSION = 7  # Update if you're using a different version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from roboflow import Roboflow\n",
    "    \n",
    "    # Download dataset\n",
    "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "    project = rf.workspace(\"gil-alon-ilxmb\").project(\"deep-learning\")\n",
    "    dataset = project.version(DATASET_VERSION).download(\"yolov8\", location=\"data/raw\")\n",
    "    \n",
    "    print(f\"✓ Dataset downloaded to: {dataset.location}\")\n",
    "else:\n",
    "    print(\"⚠️ Running locally - assuming dataset already exists\")\n",
    "    \n",
    "# Verify test set exists\n",
    "test_images = list(Path(\"data/raw/test/images\").glob(\"*.jpg\"))\n",
    "print(f\"Found {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Prerequisites\n",
    "\n",
    "Before generating occlusions, ensure:\n",
    "- ✅ Model weights exist (from Step 3.2 training)\n",
    "- ✅ Test index exists (from Step 2)\n",
    "- ✅ Scripts are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Check required files\n",
    "required_files = {\n",
    "    \"YOLOv8 weights\": \"models/yolov8n_baseline.pt\",\n",
    "    \"RT-DETR weights\": \"models/rtdetr_baseline.pt\",\n",
    "    \"Test index\": \"data/processed/evaluation/test_index.json\",\n",
    "    \"Occlusion script\": \"scripts/generate_synthetic_occlusions.py\",\n",
    "    \"Evaluation script\": \"scripts/evaluate_baseline.py\",\n",
    "    \"Data YAML helper\": \"scripts/create_data_yaml.py\"\n",
    "}\n",
    "\n",
    "all_exist = True\n",
    "for name, path in required_files.items():\n",
    "    exists = Path(path).exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "if not all_exist:\n",
    "    print(\"\\n❌ Some required files are missing!\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"  1. You've trained models in 02_train_models.ipynb\")\n",
    "    print(\"  2. You've run build_evaluation_index.py (Step 2)\")\n",
    "    print(\"  3. All scripts are present in scripts/ directory\")\n",
    "else:\n",
    "    print(\"\\n✓ All prerequisites satisfied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Occlusion Test Sets\n",
    "\n",
    "Create 4 test sets from the same 400 images:\n",
    "- `level_000/` - Original (0% occlusion) - baseline\n",
    "- `level_020/` - 20% occlusion per bbox\n",
    "- `level_040/` - 40% occlusion per bbox\n",
    "- `level_060/` - 60% occlusion per bbox\n",
    "\n",
    "**Time:** ~2-5 minutes depending on image sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate occluded test sets\n",
    "!python scripts/generate_synthetic_occlusions.py \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --images_dir data/raw/test/images \\\n",
    "    --labels_dir data/raw/test/labels \\\n",
    "    --output_dir data/synthetic_occlusion \\\n",
    "    --levels 0.0,0.2,0.4,0.6 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify occlusion test sets created\n",
    "occlusion_levels = [0, 20, 40, 60]\n",
    "occlusion_manifest_path = Path(\"data/synthetic_occlusion/occlusion_manifest.json\")\n",
    "\n",
    "if occlusion_manifest_path.exists():\n",
    "    with open(occlusion_manifest_path, 'r') as f:\n",
    "        manifest = json.load(f)\n",
    "    \n",
    "    print(\"✓ Synthetic occlusion test sets created!\\n\")\n",
    "    print(\"Levels generated:\")\n",
    "    for level_name, description in manifest['occlusion_levels'].items():\n",
    "        print(f\"  - {level_name}: {description}\")\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    for level_name, stats in manifest['statistics'].items():\n",
    "        print(f\"  {level_name}:\")\n",
    "        print(f\"    - Images: {stats['total_images']}\")\n",
    "        print(f\"    - Boxes occluded: {stats['total_boxes_occluded']}\")\n",
    "else:\n",
    "    print(\"❌ Manifest not found! Occlusion generation may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create data.yaml for Each Occlusion Level\n",
    "\n",
    "Each test set needs its own `data.yaml` for Ultralytics validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml for original test set (0% occlusion)\n",
    "!python scripts/create_data_yaml.py \\\n",
    "    --dataset_root data/raw \\\n",
    "    --output data/synthetic_occlusion/level_000/data.yaml \\\n",
    "    --absolute\n",
    "\n",
    "# Copy test images to level_000 (original, no occlusions)\n",
    "import shutil\n",
    "level_000_dir = Path(\"data/synthetic_occlusion/level_000\")\n",
    "level_000_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy original test images and labels\n",
    "for subdir in ['images', 'labels']:\n",
    "    src = Path(f\"data/raw/test/{subdir}\")\n",
    "    dst = level_000_dir / subdir\n",
    "    if dst.exists():\n",
    "        shutil.rmtree(dst)\n",
    "    shutil.copytree(src, dst)\n",
    "\n",
    "print(\"✓ Created level_000 (original test set)\")\n",
    "\n",
    "# Verify all data.yaml files exist\n",
    "print(\"\\nVerifying data.yaml files:\")\n",
    "for level in [0, 20, 40, 60]:\n",
    "    level_name = f\"level_{level:03d}\"\n",
    "    yaml_path = Path(f\"data/synthetic_occlusion/{level_name}/data.yaml\")\n",
    "    status = \"✓\" if yaml_path.exists() else \"✗\"\n",
    "    print(f\"{status} {level_name}/data.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate YOLOv8 on All Occlusion Levels\n",
    "\n",
    "Run inference with **fixed weights** (no training!).\n",
    "\n",
    "Generates 12 JSON files:\n",
    "- `yolo_000_run.json`, `yolo_000_metrics.json`, `yolo_000_predictions.json`\n",
    "- `yolo_020_run.json`, `yolo_020_metrics.json`, `yolo_020_predictions.json`\n",
    "- `yolo_040_run.json`, `yolo_040_metrics.json`, `yolo_040_predictions.json`\n",
    "- `yolo_060_run.json`, `yolo_060_metrics.json`, `yolo_060_predictions.json`\n",
    "\n",
    "**Time:** ~10 minutes total (400 images × 4 levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate YOLOv8 on 0% occlusion (baseline)\n",
    "print(\"=\" * 60)\n",
    "print(\"YOLOv8 Evaluation - 0% Occlusion (Baseline)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model yolo \\\n",
    "    --yolo_weights models/yolov8n_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_000/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id yolo_000 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate YOLOv8 on 20% occlusion\n",
    "print(\"=\" * 60)\n",
    "print(\"YOLOv8 Evaluation - 20% Occlusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model yolo \\\n",
    "    --yolo_weights models/yolov8n_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_020/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id yolo_020 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate YOLOv8 on 40% occlusion\n",
    "print(\"=\" * 60)\n",
    "print(\"YOLOv8 Evaluation - 40% Occlusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model yolo \\\n",
    "    --yolo_weights models/yolov8n_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_040/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id yolo_040 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate YOLOv8 on 60% occlusion\n",
    "print(\"=\" * 60)\n",
    "print(\"YOLOv8 Evaluation - 60% Occlusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model yolo \\\n",
    "    --yolo_weights models/yolov8n_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_060/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id yolo_060 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate RT-DETR on All Occlusion Levels\n",
    "\n",
    "Same procedure for RT-DETR.\n",
    "\n",
    "Generates 12 more JSON files:\n",
    "- `rtdetr_000_run.json`, `rtdetr_000_metrics.json`, `rtdetr_000_predictions.json`\n",
    "- `rtdetr_020_run.json`, `rtdetr_020_metrics.json`, `rtdetr_020_predictions.json`\n",
    "- `rtdetr_040_run.json`, `rtdetr_040_metrics.json`, `rtdetr_040_predictions.json`\n",
    "- `rtdetr_060_run.json`, `rtdetr_060_metrics.json`, `rtdetr_060_predictions.json`\n",
    "\n",
    "**Time:** ~10-15 minutes total (RT-DETR is slower than YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RT-DETR on 0% occlusion (baseline)\n",
    "print(\"=\" * 60)\n",
    "print(\"RT-DETR Evaluation - 0% Occlusion (Baseline)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model rtdetr \\\n",
    "    --rtdetr_weights models/rtdetr_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_000/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id rtdetr_000 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RT-DETR on 20% occlusion\n",
    "print(\"=\" * 60)\n",
    "print(\"RT-DETR Evaluation - 20% Occlusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model rtdetr \\\n",
    "    --rtdetr_weights models/rtdetr_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_020/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id rtdetr_020 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RT-DETR on 40% occlusion\n",
    "print(\"=\" * 60)\n",
    "print(\"RT-DETR Evaluation - 40% Occlusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model rtdetr \\\n",
    "    --rtdetr_weights models/rtdetr_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_040/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id rtdetr_040 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RT-DETR on 60% occlusion\n",
    "print(\"=\" * 60)\n",
    "print(\"RT-DETR Evaluation - 60% Occlusion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python scripts/evaluate_baseline.py \\\n",
    "    --model rtdetr \\\n",
    "    --rtdetr_weights models/rtdetr_baseline.pt \\\n",
    "    --data_yaml data/synthetic_occlusion/level_060/data.yaml \\\n",
    "    --test_index data/processed/evaluation/test_index.json \\\n",
    "    --output_dir evaluation/occlusion_metrics \\\n",
    "    --run_id rtdetr_060 \\\n",
    "    --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verify All JSON Files Generated\n",
    "\n",
    "Should have 24 JSON files total:\n",
    "- 8 `*_run.json` files\n",
    "- 8 `*_metrics.json` files\n",
    "- 8 `*_predictions.json` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all JSON files exist\n",
    "output_dir = Path(\"evaluation/occlusion_metrics\")\n",
    "models = ['yolo', 'rtdetr']\n",
    "levels = ['000', '020', '040', '060']\n",
    "file_types = ['run', 'metrics', 'predictions']\n",
    "\n",
    "print(\"Checking generated JSON files:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_files_exist = True\n",
    "total_files = 0\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{model.upper()} Evaluations:\")\n",
    "    for level in levels:\n",
    "        print(f\"\\n  Level {level} ({int(level)}% occlusion):\")\n",
    "        for file_type in file_types:\n",
    "            filename = f\"{model}_{level}_{file_type}.json\"\n",
    "            filepath = output_dir / filename\n",
    "            exists = filepath.exists()\n",
    "            status = \"✓\" if exists else \"✗\"\n",
    "            \n",
    "            # Get file size if exists\n",
    "            size_str = \"\"\n",
    "            if exists:\n",
    "                size_kb = filepath.stat().st_size / 1024\n",
    "                size_str = f\"({size_kb:.1f} KB)\"\n",
    "                total_files += 1\n",
    "            \n",
    "            print(f\"    {status} {filename} {size_str}\")\n",
    "            \n",
    "            if not exists:\n",
    "                all_files_exist = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nTotal files created: {total_files} / 24\")\n",
    "\n",
    "if all_files_exist:\n",
    "    print(\"✓ All 24 JSON files successfully generated!\")\n",
    "else:\n",
    "    print(\"\\n❌ Some JSON files are missing!\")\n",
    "    print(\"Check the evaluation outputs above for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare Performance Across Occlusion Levels\n",
    "\n",
    "Quick preview of the degradation curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load all metrics\n",
    "results = []\n",
    "\n",
    "for model in models:\n",
    "    for level in levels:\n",
    "        metrics_file = output_dir / f\"{model}_{level}_metrics.json\"\n",
    "        if metrics_file.exists():\n",
    "            with open(metrics_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            agg = data['aggregate_metrics']\n",
    "            results.append({\n",
    "                'Model': model.upper(),\n",
    "                'Occlusion': f\"{int(level)}%\",\n",
    "                'mAP@50': round(agg['map50'], 3),\n",
    "                'mAP@50-95': round(agg['map50_95'], 3),\n",
    "                'Precision': round(agg['precision'], 3),\n",
    "                'Recall': round(agg['recall'], 3),\n",
    "                'FPS': round(agg['fps'], 1)\n",
    "            })\n",
    "\n",
    "# Create comparison table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OCCLUSION ROBUSTNESS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degradation percentages\n",
    "print(\"\\nPerformance Degradation (compared to 0% baseline):\\n\")\n",
    "\n",
    "for model in ['YOLO', 'RTDETR']:\n",
    "    model_results = df[df['Model'] == model]\n",
    "    baseline = model_results[model_results['Occlusion'] == '0%']['mAP@50'].values[0]\n",
    "    \n",
    "    print(f\"{model}:\")\n",
    "    for _, row in model_results.iterrows():\n",
    "        if row['Occlusion'] == '0%':\n",
    "            continue\n",
    "        degradation = ((baseline - row['mAP@50']) / baseline) * 100\n",
    "        print(f\"  {row['Occlusion']:>4} occlusion: mAP@50 = {row['mAP@50']:.3f} ({degradation:+.1f}% vs baseline)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Results to Google Drive (Colab Only)\n",
    "\n",
    "Save all JSON files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Create backup directory\n",
    "    backup_dir = Path('/content/drive/MyDrive/Deep_Learning_Occlusion_Results')\n",
    "    backup_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy all JSON files\n",
    "    import shutil\n",
    "    for json_file in output_dir.glob('*.json'):\n",
    "        shutil.copy(json_file, backup_dir / json_file.name)\n",
    "    \n",
    "    print(f\"✓ Saved {len(list(output_dir.glob('*.json')))} JSON files to Google Drive\")\n",
    "    print(f\"Location: {backup_dir}\")\n",
    "else:\n",
    "    print(\"Running locally - JSON files already saved to evaluation/occlusion_metrics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary & Next Steps\n",
    "\n",
    "**What We Just Did:**\n",
    "1. ✅ Generated 4 synthetic occlusion test sets (0%, 20%, 40%, 60%)\n",
    "2. ✅ Evaluated YOLOv8 with fixed weights on all 4 levels\n",
    "3. ✅ Evaluated RT-DETR with fixed weights on all 4 levels\n",
    "4. ✅ Generated 24 JSON files (2 models × 4 levels × 3 file types)\n",
    "\n",
    "**Expected Results:**\n",
    "- Both models should degrade as occlusion increases\n",
    "- **RT-DETR should degrade LESS** than YOLOv8 at higher occlusion levels\n",
    "- This validates the hypothesis: Transformers handle occlusion better\n",
    "\n",
    "**Next Steps:**\n",
    "1. Analyze degradation curves in detail\n",
    "2. Compute per-class robustness (which ingredients are most affected?)\n",
    "3. Visualize predictions on occluded images\n",
    "4. Write up findings for project report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OCCLUSION ROBUSTNESS EVALUATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nGenerated {total_files} JSON files in: {output_dir}\")\n",
    "print(\"\\nJSON files ready for analysis:\")\n",
    "print(\"  - Run metadata: Reproducibility info\")\n",
    "print(\"  - Metrics: mAP, precision, recall, FPS\")\n",
    "print(\"  - Predictions: Per-image detections for detailed analysis\")\n",
    "print(\"\\nYou can now:\")\n",
    "print(\"  1. Commit JSON files to GitHub\")\n",
    "print(\"  2. Analyze degradation curves\")\n",
    "print(\"  3. Compare CNN vs Transformer robustness\")\n",
    "print(\"  4. Generate visualizations for report\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a5c29b",
   "metadata": {},
   "source": [
    "## 1. Setup - Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccedba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Deep_Learning_Project_Gil_Alon'...\n",
      "remote: Enumerating objects: 35, done.\u001b[K\n",
      "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
      "remote: Total 35 (delta 8), reused 24 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (35/35), 17.72 KiB | 362.00 KiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon\n"
     ]
    }
   ],
   "source": [
    "# Go to /content first, clean previous clone, then clone fresh\n",
    "%cd /content\n",
    "!rm -rf Deep_Learning_Project_Gil_Alon\n",
    "!git clone https://github.com/gil-attar/Deep_Learning_Project_Gil_Alon.git\n",
    "%cd Deep_Learning_Project_Gil_Alon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1015db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9ae38",
   "metadata": {},
   "source": [
    "## 2. Set API Keys\n",
    "\n",
    "Replace with your actual keys below, or use Colab Secrets (ðŸ”‘ icon in sidebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32241106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option A: Set directly (replace with your keys)\n",
    "os.environ[\"ROBOFLOW_API_KEY\"] = \"zEF9icmDY2oTcPkaDcQY\"\n",
    "\n",
    "# Option B: Use Colab Secrets (recommended)\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get('ROBOFLOW_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce638f4",
   "metadata": {},
   "source": [
    "## 3. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f6a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Downloading Food Ingredients Dataset\n",
      "==================================================\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/download_dataset.py\", line 148, in <module>\n",
      "    download_dataset()\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/download_dataset.py\", line 43, in download_dataset\n",
      "    dataset = project.version(4).download(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/roboflow/core/project.py\", line 357, in version\n",
      "    raise RuntimeError(f\"Version number {version_number} is not found.\")\n",
      "RuntimeError: Version number 4 is not found.\n"
     ]
    }
   ],
   "source": [
    "!python scripts/download_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd5f11",
   "metadata": {},
   "source": [
    "## 4. Split Dataset (70% train / 10% valid / 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c33eb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HYPERPARAMETER TUNING SPLIT\n",
      "============================================================\n",
      "Ratios: 70% train / 10% valid / 20% test\n",
      "Random seed: 42\n",
      "\n",
      "1. Finding dataset...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/split_dataset.py\", line 246, in <module>\n",
      "    main()\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/split_dataset.py\", line 182, in main\n",
      "    dataset_dir = find_dataset_dir()\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/split_dataset.py\", line 56, in find_dataset_dir\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Dataset not found in /content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/data/raw. Run download_dataset.py first.\n"
     ]
    }
   ],
   "source": [
    "!python scripts/split_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35120b",
   "metadata": {},
   "source": [
    "## 5. Build Evaluation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf09189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUILD EVALUATION INDEX\n",
      "============================================================\n",
      "\n",
      "1. Finding dataset...\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/build_evaluation_index.py\", line 346, in <module>\n",
      "    main()\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/build_evaluation_index.py\", line 308, in main\n",
      "    dataset_dir = find_dataset_dir()\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/Deep_Learning_Project_Gil_Alon/Deep_Learning_Project_Gil_Alon/scripts/build_evaluation_index.py\", line 51, in find_dataset_dir\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Dataset not found. Run download_dataset.py and split_dataset.py first.\n"
     ]
    }
   ],
   "source": [
    "!python scripts/build_evaluation_index.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2884d5b",
   "metadata": {},
   "source": [
    "## 6. Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a16b9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Structure ===\n",
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 Jan  8 13:00 .\n",
      "drwxr-xr-x 4 root root 4096 Jan  8 13:00 ..\n",
      "-rw-r--r-- 1 root root    0 Jan  8 13:00 .gitkeep\n",
      "\n",
      "=== Train/Valid/Test Counts ===\n",
      "ls: cannot access 'data/processed/train/images/': No such file or directory\n",
      "Train images: 0\n",
      "ls: cannot access 'data/processed/valid/images/': No such file or directory\n",
      "Valid images: 0\n",
      "ls: cannot access 'data/processed/test/images/': No such file or directory\n",
      "Test images: 0\n"
     ]
    }
   ],
   "source": [
    "# Check directory structure\n",
    "!echo \"=== Data Structure ===\"\n",
    "!ls -la data/processed/\n",
    "\n",
    "!echo \"\"\n",
    "!echo \"=== Train/Valid/Test Counts ===\"\n",
    "!echo \"Train images: $(ls data/processed/train/images/ | wc -l)\"\n",
    "!echo \"Valid images: $(ls data/processed/valid/images/ | wc -l)\"\n",
    "!echo \"Test images: $(ls data/processed/test/images/ | wc -l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "885574f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/test_index.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3523960681.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/processed/test_index.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/processed/test_index.json'"
     ]
    }
   ],
   "source": [
    "# Check the evaluation index\n",
    "import json\n",
    "\n",
    "with open('data/processed/test_index.json', 'r') as f:\n",
    "    index = json.load(f)\n",
    "\n",
    "print(\"=== Evaluation Index Summary ===\")\n",
    "print(f\"Total test images: {index['metadata']['num_images']}\")\n",
    "print(f\"Total objects: {index['metadata']['total_objects']}\")\n",
    "print(f\"Classes: {index['metadata']['num_classes']}\")\n",
    "print(f\"\\nDifficulty distribution:\")\n",
    "for diff, count in index['metadata']['difficulty_distribution'].items():\n",
    "    print(f\"  {diff}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9830201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Image Entry ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1749153228.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show a sample image entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Sample Image Entry ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "# Show a sample image entry\n",
    "print(\"=== Sample Image Entry ===\")\n",
    "sample = index['images'][0]\n",
    "print(json.dumps(sample, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0880e",
   "metadata": {},
   "source": [
    "## âœ… Data Pipeline Complete!\n",
    "\n",
    "Next steps:\n",
    "- Train models (Step 3)\n",
    "- Evaluate and compare (Step 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

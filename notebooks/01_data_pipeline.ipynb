{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a5c29b",
   "metadata": {},
   "source": [
    "# Step 2: Data Pipeline & Evaluation Foundations\n",
    "\n",
    "This notebook downloads the dataset and creates all Step 2 artifacts.\n",
    "After running this notebook, Step 2 is **FROZEN** - do not regenerate these files.\n",
    "\n",
    "## 1. Setup - Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccedba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mrequest to https://8080-m-s-32i2i9vdmt1dt-b.us-west4-1.prod.colab.dev/api/kernels/8f57e240-3a8a-49c6-8799-f11465ea64ab/restart?1767883265988 failed, reason: connect ETIMEDOUT 34.144.254.29:443. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Go to /content first, clean previous clone, then clone fresh\n",
    "%cd /content\n",
    "!rm -rf Deep_Learning_Project_Gil_Alon\n",
    "!git clone https://github.com/gil-attar/Deep_Learning_Project_Gil_Alon.git\n",
    "%cd Deep_Learning_Project_Gil_Alon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9ae38",
   "metadata": {},
   "source": [
    "## 2. Set API Keys\n",
    "\n",
    "Replace with your actual keys below, or use Colab Secrets (ðŸ”‘ icon in sidebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32241106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option A: Set directly (replace with your keys)\n",
    "os.environ[\"ROBOFLOW_API_KEY\"] = \"zEF9icmDY2oTcPkaDcQY\"\n",
    "\n",
    "# Option B: Use Colab Secrets (recommended)\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get('ROBOFLOW_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce638f4",
   "metadata": {},
   "source": [
    "## 3. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset to data/raw/ (immutable source)\n",
    "!python scripts/download_dataset.py --output_dir data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd5f11",
   "metadata": {},
   "source": [
    "## 4. Build Evaluation Index\n",
    "\n",
    "Creates all Step 2 artifacts:\n",
    "- `splits/split_manifest.json` - Lists all filenames per split\n",
    "- `evaluation/test_index.json` - Ground truth + occlusion difficulty  \n",
    "- `evaluation/difficulty_summary.csv` - Statistics per difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33eb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all Step 2 evaluation artifacts\n",
    "!python scripts/build_evaluation_index.py --dataset_root data/raw --output_dir data/processed --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2884d5b",
   "metadata": {},
   "source": [
    "## 5. Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check directory structure\n",
    "!echo \"=== Raw Data Structure ===\"\n",
    "!ls -la data/raw/\n",
    "\n",
    "!echo \"\"\n",
    "!echo \"=== Processed Artifacts ===\"\n",
    "!ls -la data/processed/\n",
    "!ls -la data/processed/splits/\n",
    "!ls -la data/processed/evaluation/\n",
    "\n",
    "!echo \"\"\n",
    "!echo \"=== Train/Valid/Test Counts ===\"\n",
    "!echo \"Train images: $(ls data/raw/train/images/ | wc -l)\"\n",
    "!echo \"Valid images: $(ls data/raw/valid/images/ | wc -l)\"\n",
    "!echo \"Test images: $(ls data/raw/test/images/ | wc -l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the evaluation index and difficulty summary\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load test index\n",
    "with open('data/processed/evaluation/test_index.json', 'r') as f:\n",
    "    index = json.load(f)\n",
    "\n",
    "print(\"=== Evaluation Index Summary ===\")\n",
    "print(f\"Total test images: {index['metadata']['num_images']}\")\n",
    "print(f\"Total objects: {index['metadata']['total_objects']}\")\n",
    "print(f\"Classes: {index['metadata']['num_classes']}\")\n",
    "print(f\"\\nDifficulty distribution (based on MAX pairwise IoU):\")\n",
    "for diff, count in index['metadata']['difficulty_distribution'].items():\n",
    "    pct = 100 * count / index['metadata']['num_images']\n",
    "    print(f\"  {diff.upper():8s}: {count:4d} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nThresholds:\")\n",
    "for diff, thresh in index['metadata']['difficulty_thresholds'].items():\n",
    "    print(f\"  {diff}: {thresh}\")\n",
    "\n",
    "# Load and display difficulty summary CSV\n",
    "print(\"\\n=== Difficulty Summary (CSV) ===\")\n",
    "df = pd.read_csv('data/processed/evaluation/difficulty_summary.csv')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9830201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 5 sample images with bounding boxes (from data/raw/)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Load class names from raw data\n",
    "with open('data/raw/data.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "class_names = config['names']\n",
    "\n",
    "# Get 5 sample images from test set\n",
    "test_images_dir = Path('data/raw/test/images')\n",
    "test_labels_dir = Path('data/raw/test/labels')\n",
    "sample_images = list(test_images_dir.glob('*.jpg'))[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    # Load image\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.name[:20] + '...', fontsize=8)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Load labels and draw boxes\n",
    "    label_path = test_labels_dir / (img_path.stem + '.txt')\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, w, h = [float(p) for p in parts[1:5]]\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    img_w, img_h = img.size\n",
    "                    x1 = (x_center - w/2) * img_w\n",
    "                    y1 = (y_center - h/2) * img_h\n",
    "                    box_w = w * img_w\n",
    "                    box_h = h * img_h\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    rect = patches.Rectangle((x1, y1), box_w, box_h, \n",
    "                                            linewidth=2, edgecolor='lime', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Add label\n",
    "                    label = class_names[class_id] if class_id < len(class_names) else f'class_{class_id}'\n",
    "                    ax.text(x1, y1-5, label, fontsize=6, color='lime', \n",
    "                           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0880e",
   "metadata": {},
   "source": [
    "## âœ… Step 2 Complete - Data Pipeline FROZEN!\n",
    "\n",
    "**Artifacts created:**\n",
    "- `data/processed/splits/split_manifest.json` - All filenames per split\n",
    "- `data/processed/evaluation/test_index.json` - Ground truth + difficulty labels\n",
    "- `data/processed/evaluation/difficulty_summary.csv` - Statistics per difficulty\n",
    "\n",
    "**Important:** These files should be committed to Git. Do NOT regenerate them.\n",
    "\n",
    "**Next steps:**\n",
    "- Step 3: Train baseline models (YOLOv8 & RT-DETR)\n",
    "- Step 4: Evaluate and compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a5c29b",
   "metadata": {},
   "source": [
    "## 1. Setup - Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ccedba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'Deep_Learning_Project_Gil_Alon'...\n",
      "remote: Enumerating objects: 65, done.\u001b[K\n",
      "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
      "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
      "remote: Total 65 (delta 29), reused 44 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (65/65), 26.03 KiB | 26.03 MiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n",
      "/content/Deep_Learning_Project_Gil_Alon\n"
     ]
    }
   ],
   "source": [
    "# Go to /content first, clean previous clone, then clone fresh\n",
    "%cd /content\n",
    "!rm -rf Deep_Learning_Project_Gil_Alon\n",
    "!git clone https://github.com/gil-attar/Deep_Learning_Project_Gil_Alon.git\n",
    "%cd Deep_Learning_Project_Gil_Alon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1015db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9ae38",
   "metadata": {},
   "source": [
    "## 2. Set API Keys\n",
    "\n",
    "Replace with your actual keys below, or use Colab Secrets (ðŸ”‘ icon in sidebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32241106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option A: Set directly (replace with your keys)\n",
    "os.environ[\"ROBOFLOW_API_KEY\"] = \"zEF9icmDY2oTcPkaDcQY\"\n",
    "\n",
    "# Option B: Use Colab Secrets (recommended)\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get('ROBOFLOW_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce638f4",
   "metadata": {},
   "source": [
    "## 3. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f6a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in FOOD-INGREDIENTS-dataset-2-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141695/141695 [00:03<00:00, 37871.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to FOOD-INGREDIENTS-dataset-2-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3980/3980 [00:01<00:00, 3007.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: /content/Deep_Learning_Project_Gil_Alon/FOOD-INGREDIENTS-dataset-2-1\n",
      "Moved train/\n",
      "Moved valid/\n",
      "Moved test/\n",
      "Copied data.yaml\n",
      "\n",
      "âœ“ Dataset ready in data/processed/\n"
     ]
    }
   ],
   "source": [
    "# Download dataset from Roboflow\n",
    "from roboflow import Roboflow\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "rf = Roboflow(api_key=os.environ[\"ROBOFLOW_API_KEY\"])\n",
    "project = rf.workspace(\"gaworkspace-utcbg\").project(\"food-ingredients-dataset-2-rewtd\")\n",
    "\n",
    "print(\"Downloading dataset...\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n",
    "\n",
    "print(f\"Downloaded to: {dataset.location}\")\n",
    "\n",
    "# Move to data/processed/\n",
    "src = Path(dataset.location)\n",
    "dest = Path(\"data/processed\")\n",
    "\n",
    "# Clean destination\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    split_dest = dest / split\n",
    "    if split_dest.exists():\n",
    "        shutil.rmtree(split_dest)\n",
    "\n",
    "# Move train, valid, test folders\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    if (src / split).exists():\n",
    "        shutil.move(str(src / split), str(dest / split))\n",
    "        print(f\"Moved {split}/\")\n",
    "\n",
    "# Copy data.yaml\n",
    "if (src / \"data.yaml\").exists():\n",
    "    shutil.copy(str(src / \"data.yaml\"), str(dest / \"data.yaml\"))\n",
    "    print(\"Copied data.yaml\")\n",
    "\n",
    "# Clean up source folder\n",
    "shutil.rmtree(src, ignore_errors=True)\n",
    "\n",
    "print(\"\\nâœ“ Dataset ready in data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd5f11",
   "metadata": {},
   "source": [
    "## 4. Build Evaluation Index\n",
    "\n",
    "(Roboflow already split the data - no need to re-split!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33eb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUILD EVALUATION INDEX\n",
      "============================================================\n",
      "\n",
      "1. Finding dataset...\n",
      "   Found: /content/Deep_Learning_Project_Gil_Alon/data/processed\n",
      "\n",
      "2. Loading class names...\n",
      "   Found 26 classes\n",
      "\n",
      "3. Processing test images...\n",
      "Found 400 test images\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "  Total images: 400\n",
      "  Total objects: 856\n",
      "  Classes: 26\n",
      "\n",
      "  Difficulty distribution:\n",
      "    EASY    :  324 (81.0%)\n",
      "    MEDIUM  :   53 (13.2%)\n",
      "    HARD    :   23 (5.8%)\n",
      "\n",
      "âœ… Saved to: /content/Deep_Learning_Project_Gil_Alon/data/processed/test_index.json\n",
      "\n",
      "Next steps:\n",
      "  1. Train models (scripts/train_models.py)\n",
      "  2. Run evaluation (scripts/evaluate_models.py)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/build_evaluation_index.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2884d5b",
   "metadata": {},
   "source": [
    "## 6. Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16b9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Structure ===\n",
      "total 540\n",
      "drwxr-xr-x 5 root root   4096 Jan  8 13:42 .\n",
      "drwxr-xr-x 4 root root   4096 Jan  8 13:38 ..\n",
      "-rw-r--r-- 1 root root    544 Jan  8 13:42 data.yaml\n",
      "-rw-r--r-- 1 root root      0 Jan  8 13:38 .gitkeep\n",
      "drwxr-xr-x 4 root root   4096 Jan  8 13:42 test\n",
      "-rw-r--r-- 1 root root 525299 Jan  8 13:42 test_index.json\n",
      "drwxr-xr-x 4 root root   4096 Jan  8 13:42 train\n",
      "drwxr-xr-x 4 root root   4096 Jan  8 13:42 valid\n",
      "\n",
      "=== Train/Valid/Test Counts ===\n",
      "Train images: 1384\n",
      "Valid images: 200\n",
      "Test images: 400\n"
     ]
    }
   ],
   "source": [
    "# Check directory structure\n",
    "!echo \"=== Data Structure ===\"\n",
    "!ls -la data/processed/\n",
    "\n",
    "!echo \"\"\n",
    "!echo \"=== Train/Valid/Test Counts ===\"\n",
    "!echo \"Train images: $(ls data/processed/train/images/ | wc -l)\"\n",
    "!echo \"Valid images: $(ls data/processed/valid/images/ | wc -l)\"\n",
    "!echo \"Test images: $(ls data/processed/test/images/ | wc -l)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885574f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Index Summary ===\n",
      "Total test images: 400\n",
      "Total objects: 856\n",
      "Classes: 26\n",
      "\n",
      "Difficulty distribution:\n",
      "  easy: 324\n",
      "  medium: 53\n",
      "  hard: 23\n"
     ]
    }
   ],
   "source": [
    "# Check the evaluation index\n",
    "import json\n",
    "\n",
    "with open('data/processed/test_index.json', 'r') as f:\n",
    "    index = json.load(f)\n",
    "\n",
    "print(\"=== Evaluation Index Summary ===\")\n",
    "print(f\"Total test images: {index['metadata']['num_images']}\")\n",
    "print(f\"Total objects: {index['metadata']['total_objects']}\")\n",
    "print(f\"Classes: {index['metadata']['num_classes']}\")\n",
    "print(f\"\\nDifficulty distribution:\")\n",
    "for diff, count in index['metadata']['difficulty_distribution'].items():\n",
    "    print(f\"  {diff}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9830201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Image Entry ===\n",
      "{\n",
      "  \"image_id\": \"-101_jpg.rf.6b25c54c2e5757525123906d817bdb5e\",\n",
      "  \"image_path\": \"data/processed/test/images/-101_jpg.rf.6b25c54c2e5757525123906d817bdb5e.jpg\",\n",
      "  \"label_path\": \"data/processed/test/labels/-101_jpg.rf.6b25c54c2e5757525123906d817bdb5e.txt\",\n",
      "  \"ground_truth\": [\n",
      "    {\n",
      "      \"class_id\": 9,\n",
      "      \"bbox_yolo\": [\n",
      "        0.6021634615384616,\n",
      "        0.1346153846153846,\n",
      "        0.46634615384615385,\n",
      "        0.2644230769230769\n",
      "      ],\n",
      "      \"class_name\": \"Capsicum\",\n",
      "      \"bbox_xyxy\": [\n",
      "        236,\n",
      "        1,\n",
      "        534,\n",
      "        170\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"class_id\": 9,\n",
      "      \"bbox_yolo\": [\n",
      "        0.5144230769230769,\n",
      "        0.4326923076923077,\n",
      "        0.36538461538461536,\n",
      "        0.44471153846153844\n",
      "      ],\n",
      "      \"class_name\": \"Capsicum\",\n",
      "      \"bbox_xyxy\": [\n",
      "        212,\n",
      "        134,\n",
      "        446,\n",
      "        419\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"num_objects\": 2,\n",
      "  \"occlusion_stats\": {\n",
      "    \"pairwise_ious\": [\n",
      "      0.0694\n",
      "    ],\n",
      "    \"avg_iou\": 0.0694,\n",
      "    \"max_iou\": 0.0694,\n",
      "    \"num_overlapping_pairs\": 1\n",
      "  },\n",
      "  \"difficulty\": \"medium\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show 5 sample images with bounding boxes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "# Load class names\n",
    "with open('data/processed/data.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "class_names = config['names']\n",
    "\n",
    "# Get 5 sample images from test set\n",
    "test_images_dir = Path('data/processed/test/images')\n",
    "test_labels_dir = Path('data/processed/test/labels')\n",
    "sample_images = list(test_images_dir.glob('*.jpg'))[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    # Load image\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.name[:20] + '...', fontsize=8)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Load labels and draw boxes\n",
    "    label_path = test_labels_dir / (img_path.stem + '.txt')\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, w, h = [float(p) for p in parts[1:5]]\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    img_w, img_h = img.size\n",
    "                    x1 = (x_center - w/2) * img_w\n",
    "                    y1 = (y_center - h/2) * img_h\n",
    "                    box_w = w * img_w\n",
    "                    box_h = h * img_h\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    rect = patches.Rectangle((x1, y1), box_w, box_h, \n",
    "                                            linewidth=2, edgecolor='lime', facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Add label\n",
    "                    label = class_names[class_id] if class_id < len(class_names) else f'class_{class_id}'\n",
    "                    ax.text(x1, y1-5, label, fontsize=6, color='lime', \n",
    "                           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0880e",
   "metadata": {},
   "source": [
    "## âœ… Data Pipeline Complete!\n",
    "\n",
    "Next steps:\n",
    "- Train models (Step 3)\n",
    "- Evaluate and compare (Step 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
